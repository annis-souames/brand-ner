{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "642e88c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gensim\n",
      "  Downloading gensim-4.1.2-cp39-cp39-win_amd64.whl (24.0 MB)\n",
      "Requirement already satisfied: numpy>=1.17.0 in c:\\users\\souam\\appdata\\roaming\\python\\python39\\site-packages (from gensim) (1.22.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in c:\\users\\souam\\anaconda3\\lib\\site-packages (from gensim) (5.2.1)\n",
      "Collecting Cython==0.29.23\n",
      "  Downloading Cython-0.29.23-cp39-cp39-win_amd64.whl (1.7 MB)\n",
      "Requirement already satisfied: scipy>=0.18.1 in c:\\users\\souam\\anaconda3\\lib\\site-packages (from gensim) (1.7.1)\n",
      "Installing collected packages: Cython, gensim\n",
      "  Attempting uninstall: Cython\n",
      "    Found existing installation: Cython 0.29.24\n",
      "    Uninstalling Cython-0.29.24:\n",
      "      Successfully uninstalled Cython-0.29.24\n",
      "Successfully installed Cython-0.29.23 gensim-4.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad6aaf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import gensim, logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c14b33a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('datasets/amazon/new_sampled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de4948ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building sentences\n",
    "\n",
    "titles = data['title'].values.tolist()\n",
    "f = lambda x : x.split(' ')\n",
    "sequences = list(map(f,titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "82b0ce0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "98828"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "54c5a806",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list(filter(lambda x: x != '',sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "47961e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 23:03:50,756 : INFO : collecting all words and their counts\n",
      "2022-01-12 23:03:50,757 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2022-01-12 23:03:50,779 : INFO : PROGRESS: at sentence #10000, processed 90541 words, keeping 26604 word types\n",
      "2022-01-12 23:03:50,801 : INFO : PROGRESS: at sentence #20000, processed 181395 words, keeping 42453 word types\n",
      "2022-01-12 23:03:50,825 : INFO : PROGRESS: at sentence #30000, processed 271550 words, keeping 55493 word types\n",
      "2022-01-12 23:03:50,848 : INFO : PROGRESS: at sentence #40000, processed 361934 words, keeping 66867 word types\n",
      "2022-01-12 23:03:50,874 : INFO : PROGRESS: at sentence #50000, processed 452396 words, keeping 77300 word types\n",
      "2022-01-12 23:03:50,897 : INFO : PROGRESS: at sentence #60000, processed 542759 words, keeping 86764 word types\n",
      "2022-01-12 23:03:50,926 : INFO : PROGRESS: at sentence #70000, processed 633201 words, keeping 95985 word types\n",
      "2022-01-12 23:03:50,950 : INFO : PROGRESS: at sentence #80000, processed 723570 words, keeping 104836 word types\n",
      "2022-01-12 23:03:50,976 : INFO : PROGRESS: at sentence #90000, processed 813606 words, keeping 113075 word types\n",
      "2022-01-12 23:03:50,999 : INFO : collected 120165 word types from a corpus of 893464 raw words and 98828 sentences\n",
      "2022-01-12 23:03:51,000 : INFO : Creating a fresh vocabulary\n",
      "2022-01-12 23:03:51,161 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 retains 42467 unique words (35.34057337827154%% of original 120165, drops 77698)', 'datetime': '2022-01-12T23:03:51.160757', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2022-01-12 23:03:51,161 : INFO : Word2Vec lifecycle event {'msg': 'effective_min_count=2 leaves 815766 word corpus (91.30373467761432%% of original 893464, drops 77698)', 'datetime': '2022-01-12T23:03:51.161768', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2022-01-12 23:03:51,380 : INFO : deleting the raw counts dictionary of 120165 items\n",
      "2022-01-12 23:03:51,382 : INFO : sample=0.001 downsamples 22 most-common words\n",
      "2022-01-12 23:03:51,383 : INFO : Word2Vec lifecycle event {'msg': 'downsampling leaves estimated 728625.1526818578 word corpus (89.3%% of prior 815766)', 'datetime': '2022-01-12T23:03:51.383753', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'prepare_vocab'}\n",
      "2022-01-12 23:03:51,744 : INFO : estimated required memory for 42467 words and 200 dimensions: 89180700 bytes\n",
      "2022-01-12 23:03:51,744 : INFO : resetting layer weights\n",
      "2022-01-12 23:03:51,790 : INFO : Word2Vec lifecycle event {'update': False, 'trim_rule': 'None', 'datetime': '2022-01-12T23:03:51.790785', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'build_vocab'}\n",
      "2022-01-12 23:03:51,791 : INFO : Word2Vec lifecycle event {'msg': 'training model with 3 workers on 42467 vocabulary and 200 features, using sg=0 hs=0 sample=0.001 negative=5 window=5 shrink_windows=True', 'datetime': '2022-01-12T23:03:51.791764', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2022-01-12 23:03:52,639 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-01-12 23:03:52,644 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-01-12 23:03:52,647 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-01-12 23:03:52,648 : INFO : EPOCH - 1 : training on 893464 raw words (728933 effective words) took 0.8s, 858500 effective words/s\n",
      "2022-01-12 23:03:53,513 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-01-12 23:03:53,514 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-01-12 23:03:53,521 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-01-12 23:03:53,522 : INFO : EPOCH - 2 : training on 893464 raw words (728786 effective words) took 0.9s, 841915 effective words/s\n",
      "2022-01-12 23:03:54,368 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-01-12 23:03:54,369 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-01-12 23:03:54,375 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-01-12 23:03:54,376 : INFO : EPOCH - 3 : training on 893464 raw words (728494 effective words) took 0.8s, 861436 effective words/s\n",
      "2022-01-12 23:03:55,199 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-01-12 23:03:55,203 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-01-12 23:03:55,207 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-01-12 23:03:55,208 : INFO : EPOCH - 4 : training on 893464 raw words (728853 effective words) took 0.8s, 885053 effective words/s\n",
      "2022-01-12 23:03:56,077 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-01-12 23:03:56,081 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-01-12 23:03:56,083 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-01-12 23:03:56,084 : INFO : EPOCH - 5 : training on 893464 raw words (728738 effective words) took 0.9s, 843158 effective words/s\n",
      "2022-01-12 23:03:56,889 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-01-12 23:03:56,895 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-01-12 23:03:56,905 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-01-12 23:03:56,905 : INFO : EPOCH - 6 : training on 893464 raw words (728555 effective words) took 0.8s, 898134 effective words/s\n",
      "2022-01-12 23:03:57,763 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-01-12 23:03:57,768 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-01-12 23:03:57,775 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-01-12 23:03:57,776 : INFO : EPOCH - 7 : training on 893464 raw words (728642 effective words) took 0.9s, 846324 effective words/s\n",
      "2022-01-12 23:03:58,571 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-01-12 23:03:58,578 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-01-12 23:03:58,579 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-01-12 23:03:58,579 : INFO : EPOCH - 8 : training on 893464 raw words (728455 effective words) took 0.8s, 915207 effective words/s\n",
      "2022-01-12 23:03:59,363 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-01-12 23:03:59,366 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-01-12 23:03:59,374 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-01-12 23:03:59,375 : INFO : EPOCH - 9 : training on 893464 raw words (728657 effective words) took 0.8s, 927217 effective words/s\n",
      "2022-01-12 23:04:00,163 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2022-01-12 23:04:00,169 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2022-01-12 23:04:00,174 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2022-01-12 23:04:00,175 : INFO : EPOCH - 10 : training on 893464 raw words (728450 effective words) took 0.8s, 919320 effective words/s\n",
      "2022-01-12 23:04:00,176 : INFO : Word2Vec lifecycle event {'msg': 'training on 8934640 raw words (7286563 effective words) took 8.4s, 869066 effective words/s', 'datetime': '2022-01-12T23:04:00.176274', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'train'}\n",
      "2022-01-12 23:04:00,177 : INFO : Word2Vec lifecycle event {'params': 'Word2Vec(vocab=42467, vector_size=200, alpha=0.025)', 'datetime': '2022-01-12T23:04:00.177274', 'gensim': '4.1.2', 'python': '3.9.7 (default, Sep 16 2021, 16:59:28) [MSC v.1916 64 bit (AMD64)]', 'platform': 'Windows-10-10.0.19041-SP0', 'event': 'created'}\n"
     ]
    }
   ],
   "source": [
    "model = gensim.models.Word2Vec(sequences, min_count=2,vector_size=200,epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "686974cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('cartridge', 0.9744598269462585),\n",
       " ('Xerox', 0.9691468477249146),\n",
       " ('Canon', 0.9683713316917419),\n",
       " ('Brother', 0.9680795669555664),\n",
       " ('CLOVER', 0.9669252038002014),\n",
       " ('Imaging', 0.9667531251907349),\n",
       " ('MPI', 0.9658995866775513),\n",
       " ('Cartridge-Black', 0.9601041078567505),\n",
       " ('LaserJet', 0.9591062068939209),\n",
       " ('ImageClass', 0.958953857421875)]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar('Dell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "460dd2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9481874"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('HP','Dell')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9784b08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.83795893"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.similarity('Xerox','Intel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "989f5cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "v = model.wv['HP'] - model.wv['Computer'] + model.wv['Laptop']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "44eba52d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('HP', 0.9715544581413269),\n",
       " ('Dell', 0.947457492351532),\n",
       " ('Canon', 0.9356963634490967),\n",
       " ('51645A', 0.9339503049850464),\n",
       " ('cartridge', 0.9334606528282166),\n",
       " ('Brother', 0.9217835664749146),\n",
       " ('Axiom', 0.9183753132820129),\n",
       " ('Toner', 0.9136387705802917),\n",
       " ('Compatible', 0.9089564085006714),\n",
       " ('Rhinotek', 0.9088978171348572)]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "03a8b1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 23:05:33,048 : INFO : storing 42467x200 projection weights into models/embeddings/w2v.txt\n"
     ]
    }
   ],
   "source": [
    "model.wv.save_word2vec_format('models/embeddings/w2v.txt', binary=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2043d9ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[i] Creating blank nlp object for language 'en'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-01-12 23:12:11.849124: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'cudart64_110.dll'; dlerror: cudart64_110.dll not found\n",
      "2022-01-12 23:12:11.849462: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "[2022-01-12 23:12:19,343] [INFO] Reading vectors from models\\embeddings\\w2v.txt\n",
      "\n",
      "0it [00:00, ?it/s]\n",
      "1832it [00:00, 18137.40it/s]\n",
      "3646it [00:00, 17325.75it/s]\n",
      "5469it [00:00, 17649.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[+] Successfully converted 42467 vectors\n",
      "[+] Saved nlp object with vectors to output directory. You can now use the path\n",
      "to it in your config as the 'vectors' setting in [initialize].\n",
      "C:\\Users\\souam\\Documents\\DS\\Projects\\brand-ner\\models\\spacy_embeddings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7295it [00:00, 17871.41it/s]\n",
      "9180it [00:00, 18155.66it/s]\n",
      "10997it [00:00, 18099.10it/s]\n",
      "12811it [00:00, 18055.01it/s]\n",
      "14637it [00:00, 18063.09it/s]\n",
      "16444it [00:00, 18009.28it/s]\n",
      "18295it [00:01, 18107.47it/s]\n",
      "20106it [00:01, 18107.11it/s]\n",
      "21941it [00:01, 18126.36it/s]\n",
      "23754it [00:01, 17911.71it/s]\n",
      "25546it [00:01, 17859.83it/s]\n",
      "27347it [00:01, 17852.40it/s]\n",
      "29154it [00:01, 17916.44it/s]\n",
      "30946it [00:01, 17858.25it/s]\n",
      "32732it [00:01, 17700.35it/s]\n",
      "34528it [00:01, 17724.82it/s]\n",
      "36301it [00:02, 17726.35it/s]\n",
      "38074it [00:02, 17623.81it/s]\n",
      "39837it [00:02, 17572.97it/s]\n",
      "41677it [00:02, 17766.21it/s]\n",
      "42467it [00:02, 17863.34it/s]\n",
      "[2022-01-12 23:12:21,726] [INFO] Loaded vectors from models\\embeddings\\w2v.txt\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy init vectors en models/embeddings/w2v.txt models/spacy_embeddings --name title_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "87745634",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('models/spacy_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4694e8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.add_pipe('ner')\n",
    "nlp.to_disk('models/spacy_embeddings')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "3951431e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    }
   ],
   "source": [
    "!python -m spacy train models/spacy_embeddings/config.cfg --output models/ner_amazon_embedding --paths.train datasets/amazon/spacy/train_shuffle.spacy --paths.dev datasets/amazon/spacy/dev_shuffle.spacy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
