{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SIEMENS NER MODEL - Flair.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Training a NER Model with Flair\n",
        "\n",
        "In this notebook we will train a NER Model using Flair (using Google Colab GPU), let's start by installing flair and importing the necessary libraires"
      ],
      "metadata": {
        "id": "Dl_hF_aw2-qQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d8ONbKPDHgo9"
      },
      "outputs": [],
      "source": [
        "!pip install flair"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from flair.data import Sentence\n",
        "from flair.models import SequenceTagger\n",
        "import logging\n",
        "import json\n",
        "#Import flair modules\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "from flair.embeddings import WordEmbeddings, FlairEmbeddings, StackedEmbeddings, BytePairEmbeddings, TransformerWordEmbeddings\n",
        "\n",
        "from flair.models import SequenceTagger\n",
        "from flair.trainers import ModelTrainer\n"
      ],
      "metadata": {
        "id": "33XAHKDrII-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will then load the data and convert the data in the BIO scheme in csv file to txt files"
      ],
      "metadata": {
        "id": "Nq2SF3u33O4S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data preparation\n",
        "data_path = '/content/drive/MyDrive/DS Projects/brand-ner/data/bio/data_bio_clean.csv'\n",
        "data_df = pd.read_csv(data_path)\n",
        "#data_df['labels'] = data_df.labels.replace('I-BRAND','B-BRAND')"
      ],
      "metadata": {
        "id": "npRUMkuDInXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a BILUO tagging scheme \n",
        "# Flair accept ner data format with word label in each line of text file with empty line for new sentence\n",
        "path = '/content/drive/MyDrive/DS Projects/brand-ner/data/bio/'\n",
        "def to_biluo(data,fn):\n",
        "  sentence_df = data.groupby('sentence_id')\n",
        "  f = open(path+fn,'w')\n",
        "  for name, sentence_grp in sentence_df:\n",
        "    for i,item in sentence_grp.iterrows():\n",
        "      word = item['words']\n",
        "      tag = item['labels']\n",
        "      f.write(f\"{word} {tag}\\n\")\n",
        "    f.write('\\n')\n"
      ],
      "metadata": {
        "id": "wzcQIryhYJvM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_df.sentence_id.max()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EUA_F4CGrIs2",
        "outputId": "bceb0cda-d011-4127-e247-13df1a3b4ece"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "98828"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's split the data into train, dev and test sets that will be used to train and evaluate the model respectively"
      ],
      "metadata": {
        "id": "QHvkVe9r3XYS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating train.txt test.txt and dev.txt\n",
        "\n",
        "idx_train = 88000\n",
        "idx_dev = 95000\n",
        "idx_test = 98828\n",
        "\n",
        "df_train = data_df[data_df.sentence_id <= idx_train]\n",
        "df_dev = data_df[(data_df.sentence_id > idx_train) & (data_df.sentence_id <= idx_dev)]\n",
        "df_test = data_df[(data_df.sentence_id > idx_dev) & (data_df.sentence_id <= idx_test)]"
      ],
      "metadata": {
        "id": "4XarQqlhiC25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c6-Ev-ipsJ-L",
        "outputId": "cd00f4e2-7f96-44c1-9cc3-451ab8931994"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1011431, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_biluo(df_train,'train.txt')\n",
        "to_biluo(df_test,'test.txt')\n",
        "to_biluo(df_dev,'dev.txt')"
      ],
      "metadata": {
        "id": "ZtyFBCORj76u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Building the model\n",
        "\n",
        "We first start by converting our txt files into a `Corpus`object that will be used by Flair to train the model, this code sinppet is grabbed from Flair documentation"
      ],
      "metadata": {
        "id": "cJQsYCiF3j_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a corpus object\n",
        "from flair.data import Corpus\n",
        "from flair.datasets import ColumnCorpus\n",
        "\n",
        "# define columns\n",
        "columns = {0: 'text', 1: 'ner',}\n",
        "\n",
        "# this is the folder in which train, test and dev files reside\n",
        "data_folder = path\n",
        "\n",
        "# init a corpus using column format, data folder and the names of the train, dev and test files\n",
        "corpus: Corpus = ColumnCorpus(data_folder, columns,\n",
        "                              train_file='train.txt',\n",
        "                              test_file='test.txt',\n",
        "                              dev_file='dev.txt')"
      ],
      "metadata": {
        "id": "jadt1DjAQ7eV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a6bf157-21af-4dfc-d14a-847b5921ef89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-13 14:18:43,877 Reading data from /content/drive/MyDrive/DS Projects/brand-ner/data/bio\n",
            "2022-01-13 14:18:43,878 Train: /content/drive/MyDrive/DS Projects/brand-ner/data/bio/train.txt\n",
            "2022-01-13 14:18:43,885 Dev: /content/drive/MyDrive/DS Projects/brand-ner/data/bio/dev.txt\n",
            "2022-01-13 14:18:43,886 Test: /content/drive/MyDrive/DS Projects/brand-ner/data/bio/test.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the size of the corpus as a basic sanity check"
      ],
      "metadata": {
        "id": "MiTX_QZW3w7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndjIiss9kqWT",
        "outputId": "fd8f4915-29bf-4ab1-f057-ddd1f571dffd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus: 87924 train + 6991 dev + 3826 test sentences\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tag type in our case is `ner`"
      ],
      "metadata": {
        "id": "-LCTfbUG31OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tag to predict\n",
        "tag_type = 'ner'\n",
        "# make tag dictionary from the corpus\n",
        "tag_dictionary = corpus.make_tag_dictionary(tag_type=tag_type)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T8nhgUePlHOI",
        "outputId": "0da569d6-b918-4280-d192-9db1d958438e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: Call to deprecated method make_tag_dictionary. (Use 'make_label_dictionary' instead.) -- Deprecated since version 0.8.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now let's build the model : \n",
        "- We will use Glove 6B and Flair embeddings on news articles in one stacked embedding\n",
        "- We use a BI-LSTM model with a crf layer at the top as explained in the paper\n",
        "- We then use the `SequenceTagger`object to train a sequence tagging model for 40 epochs using an initial learning rate of 0.1 an then reducing the learning rate every 4 bad epochs (meaning epochs with no improvement on the test set)"
      ],
      "metadata": {
        "id": "dcpw-M-a35rP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. initialize fine-tuneable transformer embeddings WITH document context\n",
        "\n",
        "embeddings = [\n",
        "              WordEmbeddings('glove'),\n",
        "              FlairEmbeddings('news-forward-fast'),\n",
        "              FlairEmbeddings('news-backward-fast')\n",
        "]\n",
        "embeddings = StackedEmbeddings(embeddings)\n",
        "\n",
        "# 5. initialize sequence tagger\n",
        "tagger = SequenceTagger(hidden_size=256,\n",
        "                        embeddings=embeddings,\n",
        "                        tag_dictionary=tag_dictionary,\n",
        "                        tag_type=tag_type,\n",
        "                        use_crf=True\n",
        "                        )\n",
        "\n",
        "# 6. initialize trainer\n",
        "trainer = ModelTrainer(tagger, corpus)\n",
        "\n"
      ],
      "metadata": {
        "id": "uiBe-1cAlPAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model and save in drive\n",
        "# 7. start training\n",
        "model_path = '/content/drive/MyDrive/DS Projects/brand-ner/models/flair/'\n",
        "model_name = 'flair-ner-new-amazon_40'\n",
        "# 7. start training\n",
        "trainer.train(model_path+model_name,\n",
        "              learning_rate=0.03,\n",
        "              mini_batch_size=32,\n",
        "              max_epochs=10,\n",
        "              embeddings_storage_mode='none'\n",
        "              )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8xWyrEh5mnF5",
        "outputId": "4fd2992a-e5c9-4306-e292-334917fe9cbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-13 18:07:34,090 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:07:34,094 Model: \"SequenceTagger(\n",
            "  (embeddings): StackedEmbeddings(\n",
            "    (list_embedding_0): WordEmbeddings(\n",
            "      'glove'\n",
            "      (embedding): Embedding(400001, 100)\n",
            "    )\n",
            "    (list_embedding_1): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.25, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 1024)\n",
            "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "    (list_embedding_2): FlairEmbeddings(\n",
            "      (lm): LanguageModel(\n",
            "        (drop): Dropout(p=0.25, inplace=False)\n",
            "        (encoder): Embedding(275, 100)\n",
            "        (rnn): LSTM(100, 1024)\n",
            "        (decoder): Linear(in_features=1024, out_features=275, bias=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (word_dropout): WordDropout(p=0.05)\n",
            "  (locked_dropout): LockedDropout(p=0.5)\n",
            "  (embedding2nn): Linear(in_features=2148, out_features=2148, bias=True)\n",
            "  (rnn): LSTM(2148, 256, batch_first=True, bidirectional=True)\n",
            "  (linear): Linear(in_features=512, out_features=6, bias=True)\n",
            "  (beta): 1.0\n",
            "  (weights): None\n",
            "  (weight_tensor) None\n",
            ")\"\n",
            "2022-01-13 18:07:34,096 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:07:34,099 Corpus: \"Corpus: 87924 train + 6991 dev + 3826 test sentences\"\n",
            "2022-01-13 18:07:34,101 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:07:34,103 Parameters:\n",
            "2022-01-13 18:07:34,105  - learning_rate: \"0.03\"\n",
            "2022-01-13 18:07:34,106  - mini_batch_size: \"32\"\n",
            "2022-01-13 18:07:34,107  - patience: \"3\"\n",
            "2022-01-13 18:07:34,108  - anneal_factor: \"0.5\"\n",
            "2022-01-13 18:07:34,109  - max_epochs: \"10\"\n",
            "2022-01-13 18:07:34,110  - shuffle: \"True\"\n",
            "2022-01-13 18:07:34,112  - train_with_dev: \"False\"\n",
            "2022-01-13 18:07:34,113  - batch_growth_annealing: \"False\"\n",
            "2022-01-13 18:07:34,114 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:07:34,115 Model training base path: \"/content/drive/MyDrive/DS Projects/brand-ner/models/flair/flair-ner-new-amazon_40\"\n",
            "2022-01-13 18:07:34,116 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:07:34,118 Device: cuda:0\n",
            "2022-01-13 18:07:34,119 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:07:34,120 Embeddings storage mode: none\n",
            "2022-01-13 18:07:34,132 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:07:52,412 epoch 1 - iter 274/2748 - loss 0.09078934 - samples/sec: 480.34 - lr: 0.030000\n",
            "2022-01-13 18:08:10,659 epoch 1 - iter 548/2748 - loss 0.08752073 - samples/sec: 481.22 - lr: 0.030000\n",
            "2022-01-13 18:08:28,666 epoch 1 - iter 822/2748 - loss 0.08707198 - samples/sec: 487.64 - lr: 0.030000\n",
            "2022-01-13 18:08:46,807 epoch 1 - iter 1096/2748 - loss 0.08655986 - samples/sec: 484.10 - lr: 0.030000\n",
            "2022-01-13 18:09:04,756 epoch 1 - iter 1370/2748 - loss 0.08648406 - samples/sec: 489.18 - lr: 0.030000\n",
            "2022-01-13 18:09:22,838 epoch 1 - iter 1644/2748 - loss 0.08654276 - samples/sec: 485.70 - lr: 0.030000\n",
            "2022-01-13 18:09:40,872 epoch 1 - iter 1918/2748 - loss 0.08645672 - samples/sec: 486.94 - lr: 0.030000\n",
            "2022-01-13 18:09:58,860 epoch 1 - iter 2192/2748 - loss 0.08633155 - samples/sec: 488.19 - lr: 0.030000\n",
            "2022-01-13 18:10:16,877 epoch 1 - iter 2466/2748 - loss 0.08667631 - samples/sec: 487.41 - lr: 0.030000\n",
            "2022-01-13 18:10:34,857 epoch 1 - iter 2740/2748 - loss 0.08676040 - samples/sec: 488.39 - lr: 0.030000\n",
            "2022-01-13 18:10:35,372 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:10:35,374 EPOCH 1 done: loss 0.0867 - lr 0.0300000\n",
            "2022-01-13 18:10:51,458 DEV : loss 0.06948589533567429 - f1-score (micro avg)  0.8253\n",
            "2022-01-13 18:10:51,524 BAD EPOCHS (no improvement): 0\n",
            "2022-01-13 18:10:51,532 saving best model\n",
            "2022-01-13 18:10:53,162 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:11:12,105 epoch 2 - iter 274/2748 - loss 0.08379107 - samples/sec: 463.80 - lr: 0.030000\n",
            "2022-01-13 18:11:30,770 epoch 2 - iter 548/2748 - loss 0.08371894 - samples/sec: 470.72 - lr: 0.030000\n",
            "2022-01-13 18:11:49,582 epoch 2 - iter 822/2748 - loss 0.08391876 - samples/sec: 466.99 - lr: 0.030000\n",
            "2022-01-13 18:12:07,742 epoch 2 - iter 1096/2748 - loss 0.08390196 - samples/sec: 483.63 - lr: 0.030000\n",
            "2022-01-13 18:12:25,984 epoch 2 - iter 1370/2748 - loss 0.08450151 - samples/sec: 481.54 - lr: 0.030000\n",
            "2022-01-13 18:12:44,178 epoch 2 - iter 1644/2748 - loss 0.08481935 - samples/sec: 482.81 - lr: 0.030000\n",
            "2022-01-13 18:13:02,513 epoch 2 - iter 1918/2748 - loss 0.08464482 - samples/sec: 478.99 - lr: 0.030000\n",
            "2022-01-13 18:13:20,856 epoch 2 - iter 2192/2748 - loss 0.08490566 - samples/sec: 478.80 - lr: 0.030000\n",
            "2022-01-13 18:13:39,351 epoch 2 - iter 2466/2748 - loss 0.08503304 - samples/sec: 474.84 - lr: 0.030000\n",
            "2022-01-13 18:13:57,506 epoch 2 - iter 2740/2748 - loss 0.08507303 - samples/sec: 483.78 - lr: 0.030000\n",
            "2022-01-13 18:13:58,050 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:13:58,051 EPOCH 2 done: loss 0.0851 - lr 0.0300000\n",
            "2022-01-13 18:14:11,027 DEV : loss 0.06887704133987427 - f1-score (micro avg)  0.8294\n",
            "2022-01-13 18:14:11,097 BAD EPOCHS (no improvement): 0\n",
            "2022-01-13 18:14:11,103 saving best model\n",
            "2022-01-13 18:14:12,585 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:14:31,718 epoch 3 - iter 274/2748 - loss 0.08429323 - samples/sec: 459.31 - lr: 0.030000\n",
            "2022-01-13 18:14:49,891 epoch 3 - iter 548/2748 - loss 0.08459945 - samples/sec: 483.35 - lr: 0.030000\n",
            "2022-01-13 18:15:07,986 epoch 3 - iter 822/2748 - loss 0.08586533 - samples/sec: 485.33 - lr: 0.030000\n",
            "2022-01-13 18:15:26,398 epoch 3 - iter 1096/2748 - loss 0.08544649 - samples/sec: 476.98 - lr: 0.030000\n",
            "2022-01-13 18:15:44,818 epoch 3 - iter 1370/2748 - loss 0.08543237 - samples/sec: 476.80 - lr: 0.030000\n",
            "2022-01-13 18:16:03,474 epoch 3 - iter 1644/2748 - loss 0.08520330 - samples/sec: 470.79 - lr: 0.030000\n",
            "2022-01-13 18:16:22,465 epoch 3 - iter 1918/2748 - loss 0.08495240 - samples/sec: 462.59 - lr: 0.030000\n",
            "2022-01-13 18:16:40,862 epoch 3 - iter 2192/2748 - loss 0.08470002 - samples/sec: 477.39 - lr: 0.030000\n",
            "2022-01-13 18:16:59,156 epoch 3 - iter 2466/2748 - loss 0.08493303 - samples/sec: 480.12 - lr: 0.030000\n",
            "2022-01-13 18:17:17,484 epoch 3 - iter 2740/2748 - loss 0.08482649 - samples/sec: 479.20 - lr: 0.030000\n",
            "2022-01-13 18:17:18,015 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:17:18,018 EPOCH 3 done: loss 0.0848 - lr 0.0300000\n",
            "2022-01-13 18:17:31,228 DEV : loss 0.06911380589008331 - f1-score (micro avg)  0.8276\n",
            "2022-01-13 18:17:31,300 BAD EPOCHS (no improvement): 1\n",
            "2022-01-13 18:17:31,307 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:17:53,136 epoch 4 - iter 274/2748 - loss 0.08426575 - samples/sec: 402.40 - lr: 0.030000\n",
            "2022-01-13 18:18:11,109 epoch 4 - iter 548/2748 - loss 0.08498910 - samples/sec: 488.64 - lr: 0.030000\n",
            "2022-01-13 18:18:29,389 epoch 4 - iter 822/2748 - loss 0.08391650 - samples/sec: 480.40 - lr: 0.030000\n",
            "2022-01-13 18:18:47,521 epoch 4 - iter 1096/2748 - loss 0.08436085 - samples/sec: 484.35 - lr: 0.030000\n",
            "2022-01-13 18:19:05,472 epoch 4 - iter 1370/2748 - loss 0.08424656 - samples/sec: 489.22 - lr: 0.030000\n",
            "2022-01-13 18:19:23,478 epoch 4 - iter 1644/2748 - loss 0.08413510 - samples/sec: 487.76 - lr: 0.030000\n",
            "2022-01-13 18:19:41,499 epoch 4 - iter 1918/2748 - loss 0.08461803 - samples/sec: 487.35 - lr: 0.030000\n",
            "2022-01-13 18:19:59,404 epoch 4 - iter 2192/2748 - loss 0.08434513 - samples/sec: 490.52 - lr: 0.030000\n",
            "2022-01-13 18:20:17,518 epoch 4 - iter 2466/2748 - loss 0.08432784 - samples/sec: 484.83 - lr: 0.030000\n",
            "2022-01-13 18:20:35,428 epoch 4 - iter 2740/2748 - loss 0.08431353 - samples/sec: 490.34 - lr: 0.030000\n",
            "2022-01-13 18:20:35,941 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:20:35,945 EPOCH 4 done: loss 0.0843 - lr 0.0300000\n",
            "2022-01-13 18:20:48,648 DEV : loss 0.0675482228398323 - f1-score (micro avg)  0.8289\n",
            "2022-01-13 18:20:48,716 BAD EPOCHS (no improvement): 2\n",
            "2022-01-13 18:20:48,722 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:21:06,604 epoch 5 - iter 274/2748 - loss 0.08131089 - samples/sec: 491.23 - lr: 0.030000\n",
            "2022-01-13 18:21:24,736 epoch 5 - iter 548/2748 - loss 0.08126914 - samples/sec: 484.34 - lr: 0.030000\n",
            "2022-01-13 18:21:42,815 epoch 5 - iter 822/2748 - loss 0.08164731 - samples/sec: 485.84 - lr: 0.030000\n",
            "2022-01-13 18:22:00,791 epoch 5 - iter 1096/2748 - loss 0.08203810 - samples/sec: 488.55 - lr: 0.030000\n",
            "2022-01-13 18:22:18,795 epoch 5 - iter 1370/2748 - loss 0.08247698 - samples/sec: 487.85 - lr: 0.030000\n",
            "2022-01-13 18:22:36,769 epoch 5 - iter 1644/2748 - loss 0.08301857 - samples/sec: 488.63 - lr: 0.030000\n",
            "2022-01-13 18:22:54,825 epoch 5 - iter 1918/2748 - loss 0.08308597 - samples/sec: 486.42 - lr: 0.030000\n",
            "2022-01-13 18:23:12,804 epoch 5 - iter 2192/2748 - loss 0.08324977 - samples/sec: 488.48 - lr: 0.030000\n",
            "2022-01-13 18:23:30,783 epoch 5 - iter 2466/2748 - loss 0.08333762 - samples/sec: 488.45 - lr: 0.030000\n",
            "2022-01-13 18:23:48,883 epoch 5 - iter 2740/2748 - loss 0.08369930 - samples/sec: 485.20 - lr: 0.030000\n",
            "2022-01-13 18:23:49,389 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:23:49,390 EPOCH 5 done: loss 0.0837 - lr 0.0300000\n",
            "2022-01-13 18:24:02,135 DEV : loss 0.06825161725282669 - f1-score (micro avg)  0.8291\n",
            "2022-01-13 18:24:02,201 BAD EPOCHS (no improvement): 3\n",
            "2022-01-13 18:24:02,206 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:24:20,292 epoch 6 - iter 274/2748 - loss 0.08343489 - samples/sec: 485.71 - lr: 0.030000\n",
            "2022-01-13 18:24:38,282 epoch 6 - iter 548/2748 - loss 0.08279860 - samples/sec: 488.16 - lr: 0.030000\n",
            "2022-01-13 18:24:56,303 epoch 6 - iter 822/2748 - loss 0.08341473 - samples/sec: 487.33 - lr: 0.030000\n",
            "2022-01-13 18:25:17,556 epoch 6 - iter 1096/2748 - loss 0.08328233 - samples/sec: 413.10 - lr: 0.030000\n",
            "2022-01-13 18:25:35,563 epoch 6 - iter 1370/2748 - loss 0.08336766 - samples/sec: 487.68 - lr: 0.030000\n",
            "2022-01-13 18:25:53,553 epoch 6 - iter 1644/2748 - loss 0.08346315 - samples/sec: 488.18 - lr: 0.030000\n",
            "2022-01-13 18:26:11,583 epoch 6 - iter 1918/2748 - loss 0.08309020 - samples/sec: 487.06 - lr: 0.030000\n",
            "2022-01-13 18:26:29,610 epoch 6 - iter 2192/2748 - loss 0.08315788 - samples/sec: 487.14 - lr: 0.030000\n",
            "2022-01-13 18:26:47,753 epoch 6 - iter 2466/2748 - loss 0.08299752 - samples/sec: 484.12 - lr: 0.030000\n",
            "2022-01-13 18:27:05,825 epoch 6 - iter 2740/2748 - loss 0.08310144 - samples/sec: 485.97 - lr: 0.030000\n",
            "2022-01-13 18:27:06,357 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:27:06,359 EPOCH 6 done: loss 0.0832 - lr 0.0300000\n",
            "2022-01-13 18:27:19,035 DEV : loss 0.06752561032772064 - f1-score (micro avg)  0.827\n",
            "Epoch     6: reducing learning rate of group 0 to 1.5000e-02.\n",
            "2022-01-13 18:27:19,103 BAD EPOCHS (no improvement): 4\n",
            "2022-01-13 18:27:19,109 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:27:37,208 epoch 7 - iter 274/2748 - loss 0.08063478 - samples/sec: 485.39 - lr: 0.015000\n",
            "2022-01-13 18:27:55,258 epoch 7 - iter 548/2748 - loss 0.08126283 - samples/sec: 486.59 - lr: 0.015000\n",
            "2022-01-13 18:28:13,303 epoch 7 - iter 822/2748 - loss 0.08052967 - samples/sec: 486.72 - lr: 0.015000\n",
            "2022-01-13 18:28:31,361 epoch 7 - iter 1096/2748 - loss 0.08050669 - samples/sec: 486.34 - lr: 0.015000\n",
            "2022-01-13 18:28:49,460 epoch 7 - iter 1370/2748 - loss 0.08003491 - samples/sec: 485.19 - lr: 0.015000\n",
            "2022-01-13 18:29:07,599 epoch 7 - iter 1644/2748 - loss 0.07987675 - samples/sec: 484.22 - lr: 0.015000\n",
            "2022-01-13 18:29:25,700 epoch 7 - iter 1918/2748 - loss 0.08020280 - samples/sec: 485.22 - lr: 0.015000\n",
            "2022-01-13 18:29:43,890 epoch 7 - iter 2192/2748 - loss 0.08055494 - samples/sec: 482.84 - lr: 0.015000\n",
            "2022-01-13 18:30:01,862 epoch 7 - iter 2466/2748 - loss 0.08050603 - samples/sec: 488.65 - lr: 0.015000\n",
            "2022-01-13 18:30:19,853 epoch 7 - iter 2740/2748 - loss 0.08083154 - samples/sec: 488.26 - lr: 0.015000\n",
            "2022-01-13 18:30:20,383 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:30:20,385 EPOCH 7 done: loss 0.0809 - lr 0.0150000\n",
            "2022-01-13 18:30:33,099 DEV : loss 0.0666913315653801 - f1-score (micro avg)  0.8321\n",
            "2022-01-13 18:30:33,165 BAD EPOCHS (no improvement): 0\n",
            "2022-01-13 18:30:33,170 saving best model\n",
            "2022-01-13 18:30:34,571 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:30:53,539 epoch 8 - iter 274/2748 - loss 0.08094398 - samples/sec: 463.26 - lr: 0.015000\n",
            "2022-01-13 18:31:11,642 epoch 8 - iter 548/2748 - loss 0.08152885 - samples/sec: 485.16 - lr: 0.015000\n",
            "2022-01-13 18:31:29,715 epoch 8 - iter 822/2748 - loss 0.08107868 - samples/sec: 485.93 - lr: 0.015000\n",
            "2022-01-13 18:31:47,862 epoch 8 - iter 1096/2748 - loss 0.08087803 - samples/sec: 483.95 - lr: 0.015000\n",
            "2022-01-13 18:32:05,943 epoch 8 - iter 1370/2748 - loss 0.08079599 - samples/sec: 485.72 - lr: 0.015000\n",
            "2022-01-13 18:32:23,983 epoch 8 - iter 1644/2748 - loss 0.08060073 - samples/sec: 486.92 - lr: 0.015000\n",
            "2022-01-13 18:32:41,930 epoch 8 - iter 1918/2748 - loss 0.08062583 - samples/sec: 489.35 - lr: 0.015000\n",
            "2022-01-13 18:33:03,211 epoch 8 - iter 2192/2748 - loss 0.08063393 - samples/sec: 412.55 - lr: 0.015000\n",
            "2022-01-13 18:33:21,327 epoch 8 - iter 2466/2748 - loss 0.08032696 - samples/sec: 484.76 - lr: 0.015000\n",
            "2022-01-13 18:33:39,401 epoch 8 - iter 2740/2748 - loss 0.08055056 - samples/sec: 485.89 - lr: 0.015000\n",
            "2022-01-13 18:33:39,919 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:33:39,922 EPOCH 8 done: loss 0.0806 - lr 0.0150000\n",
            "2022-01-13 18:33:52,751 DEV : loss 0.06734173744916916 - f1-score (micro avg)  0.833\n",
            "2022-01-13 18:33:52,816 BAD EPOCHS (no improvement): 0\n",
            "2022-01-13 18:33:52,822 saving best model\n",
            "2022-01-13 18:33:54,164 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:34:13,072 epoch 9 - iter 274/2748 - loss 0.08040324 - samples/sec: 464.89 - lr: 0.015000\n",
            "2022-01-13 18:34:31,071 epoch 9 - iter 548/2748 - loss 0.07924516 - samples/sec: 487.93 - lr: 0.015000\n",
            "2022-01-13 18:34:48,996 epoch 9 - iter 822/2748 - loss 0.08029264 - samples/sec: 489.94 - lr: 0.015000\n",
            "2022-01-13 18:35:07,112 epoch 9 - iter 1096/2748 - loss 0.08033245 - samples/sec: 484.77 - lr: 0.015000\n",
            "2022-01-13 18:35:25,096 epoch 9 - iter 1370/2748 - loss 0.08053697 - samples/sec: 488.33 - lr: 0.015000\n",
            "2022-01-13 18:35:43,226 epoch 9 - iter 1644/2748 - loss 0.08064368 - samples/sec: 484.35 - lr: 0.015000\n",
            "2022-01-13 18:36:01,313 epoch 9 - iter 1918/2748 - loss 0.08019497 - samples/sec: 485.64 - lr: 0.015000\n",
            "2022-01-13 18:36:19,269 epoch 9 - iter 2192/2748 - loss 0.08027446 - samples/sec: 489.09 - lr: 0.015000\n",
            "2022-01-13 18:36:37,255 epoch 9 - iter 2466/2748 - loss 0.08003398 - samples/sec: 488.31 - lr: 0.015000\n",
            "2022-01-13 18:36:55,536 epoch 9 - iter 2740/2748 - loss 0.08012133 - samples/sec: 480.42 - lr: 0.015000\n",
            "2022-01-13 18:36:56,063 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:36:56,064 EPOCH 9 done: loss 0.0801 - lr 0.0150000\n",
            "2022-01-13 18:37:08,967 DEV : loss 0.06685109436511993 - f1-score (micro avg)  0.8332\n",
            "2022-01-13 18:37:09,036 BAD EPOCHS (no improvement): 0\n",
            "2022-01-13 18:37:09,044 saving best model\n",
            "2022-01-13 18:37:10,474 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:37:29,435 epoch 10 - iter 274/2748 - loss 0.08093769 - samples/sec: 463.38 - lr: 0.015000\n",
            "2022-01-13 18:37:47,510 epoch 10 - iter 548/2748 - loss 0.08045367 - samples/sec: 485.88 - lr: 0.015000\n",
            "2022-01-13 18:38:05,549 epoch 10 - iter 822/2748 - loss 0.07953838 - samples/sec: 486.82 - lr: 0.015000\n",
            "2022-01-13 18:38:23,593 epoch 10 - iter 1096/2748 - loss 0.07947277 - samples/sec: 486.79 - lr: 0.015000\n",
            "2022-01-13 18:38:41,654 epoch 10 - iter 1370/2748 - loss 0.07952839 - samples/sec: 486.21 - lr: 0.015000\n",
            "2022-01-13 18:38:59,681 epoch 10 - iter 1644/2748 - loss 0.07956196 - samples/sec: 487.18 - lr: 0.015000\n",
            "2022-01-13 18:39:17,879 epoch 10 - iter 1918/2748 - loss 0.07951828 - samples/sec: 482.76 - lr: 0.015000\n",
            "2022-01-13 18:39:35,911 epoch 10 - iter 2192/2748 - loss 0.07972724 - samples/sec: 487.06 - lr: 0.015000\n",
            "2022-01-13 18:39:53,900 epoch 10 - iter 2466/2748 - loss 0.07960230 - samples/sec: 488.30 - lr: 0.015000\n",
            "2022-01-13 18:40:15,182 epoch 10 - iter 2740/2748 - loss 0.07972774 - samples/sec: 412.57 - lr: 0.015000\n",
            "2022-01-13 18:40:15,707 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:40:15,709 EPOCH 10 done: loss 0.0797 - lr 0.0150000\n",
            "2022-01-13 18:40:28,604 DEV : loss 0.0662868544459343 - f1-score (micro avg)  0.8329\n",
            "2022-01-13 18:40:28,671 BAD EPOCHS (no improvement): 1\n",
            "2022-01-13 18:40:30,035 ----------------------------------------------------------------------------------------------------\n",
            "2022-01-13 18:40:30,041 loading file /content/drive/MyDrive/DS Projects/brand-ner/models/flair/flair-ner-new-amazon_40/best-model.pt\n",
            "2022-01-13 18:40:37,635 0.8477\t0.8219\t0.8346\t0.7183\n",
            "2022-01-13 18:40:37,637 \n",
            "Results:\n",
            "- F-score (micro) 0.8346\n",
            "- F-score (macro) 0.6574\n",
            "- Accuracy 0.7183\n",
            "\n",
            "By class:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "       BRAND     0.8474    0.8301    0.8387      3779\n",
            "           -     0.9091    0.3226    0.4762        62\n",
            "\n",
            "   micro avg     0.8477    0.8219    0.8346      3841\n",
            "   macro avg     0.8782    0.5763    0.6574      3841\n",
            "weighted avg     0.8484    0.8219    0.8328      3841\n",
            " samples avg     0.7183    0.7183    0.7183      3841\n",
            "\n",
            "2022-01-13 18:40:37,641 ----------------------------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'dev_loss_history': [tensor(0.0695, device='cuda:0'),\n",
              "  tensor(0.0689, device='cuda:0'),\n",
              "  tensor(0.0691, device='cuda:0'),\n",
              "  tensor(0.0675, device='cuda:0'),\n",
              "  tensor(0.0683, device='cuda:0'),\n",
              "  tensor(0.0675, device='cuda:0'),\n",
              "  tensor(0.0667, device='cuda:0'),\n",
              "  tensor(0.0673, device='cuda:0'),\n",
              "  tensor(0.0669, device='cuda:0'),\n",
              "  tensor(0.0663, device='cuda:0')],\n",
              " 'dev_score_history': [0.825299890948746,\n",
              "  0.8294460641399417,\n",
              "  0.8276462901118049,\n",
              "  0.8288561525129983,\n",
              "  0.8290814482908145,\n",
              "  0.8269986893840106,\n",
              "  0.8321242019733025,\n",
              "  0.8329950710350826,\n",
              "  0.8331889081455806,\n",
              "  0.832900057770075],\n",
              " 'test_score': 0.8346331791143424,\n",
              " 'train_loss_history': [0.08673060131197435,\n",
              "  0.08505247087363507,\n",
              "  0.08484259411130574,\n",
              "  0.08429876052265409,\n",
              "  0.08368341124656554,\n",
              "  0.08316223712903896,\n",
              "  0.08086903610179365,\n",
              "  0.08055416628803765,\n",
              "  0.0801453448163603,\n",
              "  0.07973682733006898]}"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing the model\n",
        "\n",
        "Nice, the model is trained and is saved in our Google Drive (or Laptop), let's test it on some real world examples"
      ],
      "metadata": {
        "id": "Mmq-_5zN4lxO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the model\n",
        "\n",
        "texts = [\n",
        "    \"Laptop Dell Inspiron X546\",\n",
        "    'Black Pelikan Pencil 16mm',\n",
        "    'Battery Smart Energy by Energizer',\n",
        "    'Fijutsu DSLR Camera 156p',\n",
        "    \"Genuine Paul Smith Men's Belt-Leather Woven Plait Belt/BNWT/Sz: 36'/RRP:110.00\",\n",
        "    'Computer HP X80 Intel Xeon',\n",
        "    'Smart Watch Apple',\n",
        "    'Computer Big Hewelett-Packard Intel Xeon',\n",
        "    '24 Buttermilk oz Oroweat Bread,',\n",
        "    'Black pencil Vertex',\n",
        "    'Wireless mouse MacTech',\n",
        "    'Smart Mouse Logitech',\n",
        "    'Brother Printer V167 Black Ink',\n",
        "\n",
        "]\n",
        "\n",
        "\n",
        "trained_model_path = '/content/drive/MyDrive/DS Projects/brand-ner/models/flair/flair-ner-new-amazon_40/best-model.pt'\n",
        "flair_model =  SequenceTagger.load(trained_model_path)\n",
        "#flair_model = SequenceTagger.load('/content/flair-ner-base-transf/final-model.pt')\n",
        "for t in texts : \n",
        "  # create example sentence\n",
        "  sentence = Sentence(t)\n",
        "  # predict the tags\n",
        "  flair_model.predict(sentence)\n",
        "  print(sentence.to_tagged_string())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuTowDBwqySV",
        "outputId": "aa4e11de-9e23-41a2-a027-40aa6100bdf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-01-13 19:26:33,450 loading file /content/drive/MyDrive/DS Projects/brand-ner/models/flair/flair-ner-new-amazon_40/best-model.pt\n",
            "Laptop Dell <B-BRAND> Inspiron X546\n",
            "Black Pelikan <B-BRAND> Pencil 16mm\n",
            "Battery Smart Energy by Energizer <B-BRAND>\n",
            "Fijutsu <B-BRAND> DSLR Camera 156p\n",
            "Genuine Paul <B-BRAND> Smith <I-BRAND> Men 's Belt-Leather Woven Plait Belt / BNWT / Sz : 36 '/ RRP : 110.00\n",
            "Computer HP X80 Intel <B-BRAND> Xeon\n",
            "Smart <B-BRAND> Watch <I-BRAND> Apple\n",
            "Computer Big Hewelett-Packard <B-BRAND> Intel Xeon\n",
            "24 Buttermilk oz Oroweat <B-BRAND> Bread ,\n",
            "Black pencil Vertex <B-BRAND>\n",
            "Wireless mouse MacTech <B-BRAND>\n",
            "Smart Mouse Logitech <B-BRAND>\n",
            "Brother <B-BRAND> Printer <I-BRAND> V167 Black Ink\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model gives nice results indeed, we can now deploy it, but before doing so we should write a function that parse the B-BRAND and I-BRAND tag in each sentence and return it as an end results. There are several ways to achieve this so we will not include it in this notebook."
      ],
      "metadata": {
        "id": "tpHS4PFI42dQ"
      }
    }
  ]
}